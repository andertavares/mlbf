{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Moshe's idea:\n",
    "1. Start with a large Boolean formula f (say, industrial SAT benchmark).\n",
    "2. Generate many samples satisfying f or \\neg f.\n",
    "(Using, for example, [https://www.nature.com/articles/s42256-018-0002-3](https://www.nature.com/articles/s42256-018-0002-3))\n",
    "3. Train a DNN on this labeled sample.\n",
    "4. Check whether it is a good apprcximation of f.\n",
    "----------\n",
    "To use this notebook, please install pysat: https://pysathq.github.io/installation.html\n",
    "Perhaps the simplest way is with the following command: pip install python-sat[pblib,aiger]\n",
    "(pysat might not work on Windows)\n",
    "'''\n",
    "\n",
    "\n",
    "# This is just a warm-up cell, to see how pysat works and to generate random unsat assignments\n",
    "\n",
    "# some examples of pysat usage at: https://github.com/pysathq/pysat/blob/master/examples/usage.py\n",
    "from pysat.solvers import Glucose3\n",
    "from pysat.formula import CNF\n",
    "import random\n",
    "f = CNF(from_clauses=[[-1, 2], [3]])\n",
    "\n",
    "g = Glucose3(bootstrap_with=f)\n",
    "\n",
    "positives = list(g.enum_models())\n",
    "print('f: ', f.clauses)\n",
    "print('positives: ', positives)\n",
    "g.delete()\n",
    "\n",
    "negatives = set()\n",
    "while len(negatives) < len(positives) and len(negatives) + len(positives) < 6:\n",
    "    # generates a random assignment and adds it to the list of negatives if\n",
    "    # it does NOT satisfy f\n",
    "    candidate = [x * random.choice([-1, 1]) for x in range(1, f.nv+1)]\n",
    "    # problematic one is: candidate:  [-1, -2, 3]\n",
    "    print('candidate: ', candidate)\n",
    "    \n",
    "    # avoids generating duplicate instances\n",
    "    if tuple(candidate) in negatives:\n",
    "        #print(f'duplicate {candidate} detected')\n",
    "        continue\n",
    "\n",
    "    for clause in f.clauses:\n",
    "        # print('clause:', clause)\n",
    "        # if multiplication is positive, then literal evaluates to true\n",
    "        c_true = False\n",
    "        for l in clause: # l stands for 'literal'\n",
    "            c_true = c_true or candidate[abs(l)-1] * l > 0\n",
    "            print(f'l={l}, c={candidate[abs(l)-1]}, l*c<0? {candidate[abs(l)-1] * l < 0}, cTrue? {c_true}')\n",
    "            \n",
    "        # if variable and literal disagree on sign, result is False; if all are false in the clause\n",
    "        # we found a unsatisfying assignment\n",
    "        if all([candidate[abs(l)-1] * l < 0 for l in clause]) == False: \n",
    "            print(f'{candidate} evaluated to false, adding to negatives')\n",
    "            negatives.add(tuple(candidate))\n",
    "            break\n",
    "print('negatives:', negatives)\n",
    "        #satisfied = all([any(x) for ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to use this cell, extract bw_large.d.cnf from instances/blocksworld.tar.gz\n",
    "# blocksworld is from satlib at https://www.cs.ubc.ca/~hoos/SATLIB/Benchmarks/SAT/PLANNING/BlocksWorld/blocksworld.tar.gz\n",
    "# satlib website: https://www.cs.ubc.ca/~hoos/SATLIB/benchm.html\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "from pysat.solvers import Glucose3, Solver, NoSuchSolverError\n",
    "from pysat.formula import CNF\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "\n",
    "\n",
    "def generate_dataset(cnf_file, solver_name='Glucose3', max_samples=10):\n",
    "    \"\"\"\n",
    "    Generates a dataset from the boolean formula in the informed CNF file.\n",
    "    Particularly, it enumerates all satisfying samples with a SAT solver.\n",
    "    Then it generates the same number of unsat samples.\n",
    "    Unsat samples are generated by flipping one bit of a sat sample.\n",
    "\n",
    "    All samples are shuffled and assembled into two dataframes.\n",
    "    The first dataframe contains the binary (0/1) inputs.\n",
    "    The second dataframe contains the corresponding binary label (0/1) for unsat/sat,\n",
    "    respectively.\n",
    "\n",
    "    :param cnf_file: path to the file in CNF (Dimacs) format (see https://people.sc.fsu.edu/~jburkardt/data/cnf/cnf.html)\n",
    "    :param solver_name: name of the solver to generate the positive instances\n",
    "    :param max_samples: maximum number of samples, half of them will be positive, half negative\n",
    "    :return: tuple with 2 dataframes: inputs and labels\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f'Reading boolean formula from {cnf_file}.')\n",
    "    formula = CNF(from_file=cnf_file)\n",
    "\n",
    "    # num_vars = formula.nv\n",
    "    unsat_list = []\n",
    "\n",
    "    print(f'Finding satisfiable assignments with {solver_name}')\n",
    "    try:\n",
    "        with Solver(name=solver_name, bootstrap_with=formula) as solver:\n",
    "\n",
    "            # for each positive (sat) instance, flip a literal to generate a negative (unsat) instance\n",
    "\n",
    "            # generates the satisfying instances by querying the solver\n",
    "            sat_list = []\n",
    "            for i, solution in enumerate(solver.enum_models()):\n",
    "                sat_list.append(solution)\n",
    "                if i+1 >= max_samples / 2:  # adds 1 to index as it starts at zero\n",
    "                    print(f\"Limit number of {max_samples/2} positive samples reached.\")\n",
    "                    break\n",
    "\n",
    "            print(f'Found {len(sat_list)} sat instances.')\n",
    "            if len(sat_list) == 0:\n",
    "                print('WARNING: No sat instance found, returning empty dataset.')\n",
    "                return [], []\n",
    "\n",
    "            print('Generating the same number of unsat instances.')\n",
    "\n",
    "            # transforming each sat instance into tuple eases the generation of negative instances\n",
    "            sat_set = set([tuple(s) for s in sat_list])  # set is much quicker to verify an existing instance\n",
    "\n",
    "            for assignment in sat_list:\n",
    "                for i, literal in enumerate(assignment):\n",
    "                    tentative_unsat = list(assignment)\n",
    "                    tentative_unsat[i] = -tentative_unsat[i]  # negating one literal\n",
    "                    if tuple(tentative_unsat) not in sat_set:\n",
    "                        unsat_list.append(tentative_unsat)\n",
    "                        break  # goes on to next assignment\n",
    "                    # print(f'negated {i}-th')\n",
    "    except NoSuchSolverError as e:\n",
    "        print(f'ERROR: no solver named \"{solver_name}\" was found. '\n",
    "              f'Please use one of the names in '\n",
    "              f'https://pysathq.github.io/docs/html/api/solvers.html#pysat.solvers.SolverNames'\n",
    "              f', such as Glucose3, for example. Exiting.')\n",
    "        sys.exit(0)\n",
    "\n",
    "    # sat_list.append(sat_list[0]) ## uncomment to test duplicates\n",
    "    \n",
    "    # appends the labels (1 to sat samples, 0 to unsat samples)\n",
    "    for sat in sat_list:\n",
    "        sat.append(1)\n",
    "    for unsat in unsat_list:\n",
    "        unsat.append(0)\n",
    "\n",
    "    print(f'Preparing dataset.')\n",
    "    # concats and shuffles the two lists\n",
    "    all_data = sat_list + unsat_list\n",
    "    # random.seed(2) # uncomment to debug (otherwise each shuffle will give a different array)\n",
    "    random.shuffle(all_data)\n",
    "\n",
    "    # column names = [x1, x2, ..., xn, f] (each x_i is a variable and f is the label)\n",
    "    input_names = [f'x{i}' for i in range(1, len(all_data[0]))]\n",
    "    df = pd.DataFrame(all_data, columns=input_names + ['f'])\n",
    "    if any(df.duplicated(input_names)):\n",
    "        print('ERROR: there are duplicate entries in the dataset. Returning empty.')\n",
    "        return [], []\n",
    "\n",
    "    # replaces negatives by 0 and positives by 1\n",
    "    df.mask(df < 0, 0, inplace=True)\n",
    "    df.mask(df > 0, 1, inplace=True)\n",
    "\n",
    "    # breaks into input features & label\n",
    "    data_x = df.drop('f', axis=1)\n",
    "    data_y = df['f']\n",
    "\n",
    "    return data_x, data_y\n",
    "\n",
    "def run_model(model, data_x, data_y, splitter=StratifiedKFold(n_splits=5)):\n",
    "    '''\n",
    "    Runs a machine learning model in the dataset\n",
    "    '''\n",
    "    \n",
    "    # prints the header\n",
    "    print('#instances\\tprec\\tacc')\n",
    "\n",
    "    # trains the model for each split (fold)\n",
    "    for train_index, test_index in splitter.split(data_x, data_y):\n",
    "        # splits the data frames in test and train\n",
    "        train_x, train_y = data_x.iloc[train_index], data_y.iloc[train_index]\n",
    "        test_x, test_y = data_x.iloc[test_index], data_y.iloc[test_index]\n",
    "        \n",
    "        model.fit(train_x, train_y)\n",
    "\n",
    "        # obtains the predictions on the test set\n",
    "        predictions = model.predict(test_x)\n",
    "\n",
    "        # calculates and reports some metrics\n",
    "        acc = accuracy_score(predictions, test_y)\n",
    "        prec = precision_score(predictions, test_y, average='macro')\n",
    "        print('{}\\t\\t{:.3f}\\t{:.3f}'.format(len(test_y), prec, acc))\n",
    " \n",
    "\n",
    "\n",
    "data_x, data_y = generate_dataset('instances/bw_large.d.cnf')\n",
    "\n",
    "print('Decision tree')\n",
    "learner = DecisionTreeClassifier()\n",
    "run_model(learner, data_x, data_y ) #default is stratified 5-fold cross validati\n",
    "#run_model(learner, data_x, data_y, StratifiedShuffleSplit(n_splits=1, test_size=0.10)) # test with holdout of 10% for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate dataset using unigen2\n",
    "import re\n",
    "import os\n",
    "\n",
    "def generate_dataset(cnf_file, max_samples=1000):\n",
    "    \"\"\"\n",
    "    Uses Unigen2 (https://bitbucket.org/kuldeepmeel/unigen) to generate a dataset\n",
    "    :param cnf_file:\n",
    "    :param max_samples:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    import subprocess\n",
    "    \n",
    "    tmp_dir = '/tmp/unigen'\n",
    "\n",
    "    # makes sure that unigen working dir exists\n",
    "    os.makedirs(tmp_dir, exist_ok=True)\n",
    "\n",
    "    '''\n",
    "    unigen is called with: python UniGen2.py [options] cnf_file output\n",
    "    We'll call python from the command line as it is not straightforward to \n",
    "    import unigen and instantiate its parameters directly\n",
    "    '''\n",
    "\n",
    "    # saves the current dir, the input name (filename w/o extension) and\n",
    "    # absolute path to the input\n",
    "    current_dir = os.getcwd()\n",
    "    cnf_name = os.path.splitext(os.path.basename(cnf_file))[0]\n",
    "    cnf_abspath = os.path.abspath(cnf_file)\n",
    "\n",
    "    # enters unigen dir and generates samples for f and ~f\n",
    "    #os.chdir('unigen')\n",
    "    # generates positive samples (calls unigen on the formula from cnf_file)\n",
    "    '''\n",
    "    ret_code = subprocess.call(\n",
    "        f'python UniGen2.py -samples={max_samples//2} -runIndex=0 '\n",
    "        f'{cnf_abspath} {self.tmp_dir}'.split(' ')  # split because call accepts an array\n",
    "    )\n",
    "    if ret_code != 0:\n",
    "        print(\"WARNING! there has been some error with unigen's execution. \"\n",
    "              \"Please check the output above.\")\n",
    "    '''\n",
    "    # the file with the positive samples is self.tmp_dir/cnf_file_0.txt\n",
    "    with open(os.path.join(tmp_dir, f'{cnf_name}_0.txt')) as sample_file:\n",
    "        for line in sample_file.readlines():\n",
    "            # format of each line: v1 2 ... N 0:M, where 1 2 ... N are the variables (asserted or negated)\n",
    "            #print(line)\n",
    "            #match = re.match('v(\\d*)', line.strip())\n",
    "            str_assignments = line.strip()[1:].split(' ')[:-1]\n",
    "            \n",
    "\n",
    "    # comes back to the original dir\n",
    "    os.chdir(current_dir)\n",
    "    \n",
    "generate_dataset('instances/bw_large.d.cnf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
