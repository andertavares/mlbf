#!/bin/bash
#SBATCH --nodes=1            #Numero de Nós
#SBATCH --ntasks-per-node=16 #Numero de tarefas por Nó
#SBATCH --ntasks=16           #Numero total de tarefas MPI
#SBATCH -p tupi
#SBATCH -J mlbf         #Nome job
#SBATCH --exclusive          #Utilização exclusiva dos nós durante a execução do job
#SBATCH --output=logs/%x_%j.out
#SBATCH --error=logs/%x_%j.err

#SBATCH --mail-type=BEGIN,END,FAIL,TIME_LIMIT
#SBATCH --mail-user=andersonrochatavares@gmail.com

#SBATCH --time=1-00:00:00

# sets the nodes to use
nodeset -e $SLURM_JOB_NODELIST

#cd $SLURM_SUBMIT_DIR

# copia os arquivos
cp -r $HOME/mlsat $SCRATCH/mlsat

# configura o script
cd $SCRATCH/mlsat
conda activate mlsat
SCRIPT="python run_instances.py $1 --output $2"

# carrega o java 11 e o python3
#module load java/jdk-11
#module load python/3.7.2

srun --resv-ports  --nodes 1 --ntasks=1 -c 16 $SCRIPT

wait

######## manual alloc & exec:
# byobu
# salloc -p tupi -J mlbf -t 1-00:00:00 --exclusive
# ssh tupi
# cd mlbf
# conda activate mlsat
# srun --resv-ports  --nodes 1 --ntasks=1 -c 16 python run_instances.py $1 --output $2

# tacas15: for i in instances/tacas15/*.cnf; do srun --resv-ports  --nodes 1 --ntasks=1 -c 48 python mlbf/main.py $i --output tacas15.csv; done
# #neurons: for i in *.cnf; do srun --resv-ports  --nodes 1 --ntasks=1 -c 48 python mlbf/mlpsize.py $i --output num_neurons_satlib-uf.csv --mlp_activation=logistic --max_neurons=512; done